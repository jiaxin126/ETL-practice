{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3d719e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from datetime import datetime,timedelta\n",
    "from pandas.io.parquet import to_parquet\n",
    "from io import StringIO, BytesIO\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a633b44",
   "metadata": {},
   "source": [
    "# Adapter layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0f8c5a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all functions interact with external\n",
    "\n",
    "# read files from s3 and transfer to dataframe format\n",
    "#default decoding='utf-8'\n",
    "#default seperator=','\n",
    "def read_csv_to_df(bucket, key, decoding='utf-8',sep=','):\n",
    "    csv_obj = bucket.Object(key=key).get().get('Body').read().decode(decoding)\n",
    "    data = StringIO(csv_obj)\n",
    "    df = pd.read_csv(data, delimiter=sep)\n",
    "    return df\n",
    "\n",
    "#write parquet file to s3\n",
    "def write_df_to_s3(bucket, df, key):\n",
    "    out_buffer = BytesIO()\n",
    "    df.to_parquet(out_buffer, index=False)\n",
    "    bucket.put_object(Body=out_buffer.getvalue(), Key=key)\n",
    "    return True\n",
    "\n",
    "#write csv file to s3\n",
    "def write_df_to_s3_csv(bucket, df, key):\n",
    "    out_buffer = StringIO()\n",
    "    df.to_csv(out_buffer, index=False)\n",
    "    bucket.put_object(Body=out_buffer.getvalue(), Key=key)\n",
    "    return True\n",
    "\n",
    "#get a list of file\n",
    "def list_files_in_prefix(bucket,prefix):\n",
    "    #filter by date\n",
    "    files=[obj.key for obj in bucket.objects.filter(Prefix=prefix)]\n",
    "    return files    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8907f72",
   "metadata": {},
   "source": [
    "# Application layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a12c4071",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract, transform, load\n",
    "\n",
    "#input bucket and objects, output a dataframe\n",
    "def extract(bucket, date_list):\n",
    "    #get objects\n",
    "    objects=[key for date in date_list for key in list_files_in_prefix(bucket,date)]\n",
    "    #read from s3\n",
    "    df = pd.concat([read_csv_to_df(bucket, obj) for obj in objects], ignore_index=True)\n",
    "    return df\n",
    "\n",
    "def transform_report1(df,columns,arg_date):\n",
    "        #select colums that we need\n",
    "    df = df.loc[:, columns]\n",
    "        #dealling with missing value, drop rows with missing value\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    \n",
    "        #Get opening price and closing price per ISIN and day\n",
    "    #every day the earliest price is the opening price\n",
    "    #transform('first'):for each ISIN, Date, get the first price\n",
    "    df['opening_price']=df.sort_values(by=['Time']).groupby(['ISIN','Date'])['StartPrice'].transform('first')\n",
    "\n",
    "    #every day, the last price is the closing price\n",
    "    df['closing_price']=df.sort_values(by=['Time']).groupby(['ISIN','Date'])['EndPrice'].transform('last')\n",
    "    \n",
    "    \n",
    "        #aggregation\n",
    "    df=df.groupby(['ISIN','Date'], as_index=False).agg(opening_price_eur=('opening_price','min'),closing_price_eur=('closing_price','min'),\n",
    "                                                           minimum_price_eur=('MinPrice','min'),maximum_price_eur=('MaxPrice','max'),daily_traded_volume=('TradedVolume','sum'))\n",
    "    #if as_index=True, then ISIN and Date would be index\n",
    "    # for each ISIN and for each Date, we only have one entry\n",
    "    \n",
    "    \n",
    "        #Percent change prev closing\n",
    "    #shift(1) lag one row \n",
    "    df['prev_closing_price']=df.sort_values(by=['Date']).groupby(['ISIN'])['closing_price_eur'].shift(1)\n",
    "    #caculate percentage\n",
    "    df['change_prev_closing_%']=((df['closing_price_eur']-df['prev_closing_price'])/df['prev_closing_price'])*100\n",
    "    #drop unuseful column, and reset index\n",
    "    df.drop(columns=['prev_closing_price'],inplace=True)\n",
    "\n",
    "    #change decimal\n",
    "    df=df.round(decimals=2)\n",
    "\n",
    "    #sanity check, date shouldn't less than arg_date\n",
    "    df=df[df.Date >= arg_date]\n",
    "    return df\n",
    "\n",
    "def load(bucket, df,trg_key,trg_format,meta_key,extract_date_list):\n",
    "    #key of object that we upload to the s3\n",
    "    key = trg_key + datetime.today().strftime(\"%Y%m%d_%H%M%S\") + trg_format\n",
    "    write_df_to_s3(bucket, df, key)\n",
    "    #renew meta file\n",
    "    update_meta_file(bucket,meta_key,extract_date_list)\n",
    "    return True\n",
    "  \n",
    "#pipeline\n",
    "def etl_report1(src_bucket,trg_bucket,date_list,columns,arg_date,trg_key,trg_format,meta_key):\n",
    "    df=extract(src_bucket, date_list)\n",
    "    df=transform_report1(df,columns,arg_date)\n",
    "    extract_date_list=[date for date in date_list if date >=arg_date]\n",
    "    load(trg_bucket, df,trg_key,trg_format,meta_key,extract_date_list) \n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6483f9a0",
   "metadata": {},
   "source": [
    "# Application Function - not core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1ee53ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get date list,export severals days' raw data\n",
    "def return_date_list(bucket, arg_date,src_format,meta_key):\n",
    "    #date minus 1\n",
    "    start = datetime.strptime(arg_date, src_format).date() - timedelta(days=1)\n",
    "    today=datetime.today().date()\n",
    "    \n",
    "    #if there's no meta file\n",
    "    try:\n",
    "            #meta file for job control: sometimes some job fails, we don't want to process all jobs.\n",
    "        #first step: get all dates from min_date to today\n",
    "        df_meta=read_csv_to_df(bucket,meta_key)\n",
    "\n",
    "            #second step: get loaded dateds, some dates disappear maybe because of some reasons\n",
    "        dates = [start + timedelta(days=x) for x in range(0, (today - start).days + 1)]\n",
    "        src_dates = set(pd.to_datetime(df_meta['source_date']).dt.date)\n",
    "            #third step: remove dates that we've already processed, make date start from the minimum date\n",
    "        dates_missing = set(dates[1:]) - src_dates\n",
    "\n",
    "        #sometimes if arg_date=today_str, dates would be an empty list, there will be an error\n",
    "        if dates_missing:\n",
    "            min_date = min(set(dates[1:]) - src_dates) - timedelta(days=1)\n",
    "            #[1:] we've already minus one day\n",
    "            #[dates[1:]: datetime.date(2022, 9, 23), datetime.date(2022, 9, 24), datetime.date(2022, 9, 25)]\n",
    "            #min_date=2022-09-23\n",
    "\n",
    "                #final result\n",
    "            return_dates = [date.strftime(src_format) for date in dates if date >= min_date]\n",
    "            #return_dates=['2022-09-23', '2022-09-24', '2022-09-25']\n",
    "            #it's okay, if it's duplicated\n",
    "            return_min_date = (min_date+timedelta(days=1)).strftime(src_format)\n",
    "        else:\n",
    "            return_dates = []\n",
    "            return_min_date = datetime(2200, 1, 1).date()\n",
    "    except bucket.session.client('s3').execptions.NoSuchKey:\n",
    "        return_date_list= [(min_date+timedelta(days=x)).strftime(src_format) for x in range(0,(today-min_date).days+1)]\n",
    "        return_min_date = arg_date\n",
    "    return return_min_date, return_dates\n",
    "\n",
    "#update meta file\n",
    "def update_meta_file(bucket,meta_key,extract_date_list):\n",
    "    df_new=pd.DataFrame(columns=['source_date','datetime_of_processing'])\n",
    "    df_new['source_date']=extract_date_list\n",
    "    df_new['datetime_of_processing']= datetime.today().strftime('%Y-%m-%d')\n",
    "    df_old=read_csv_to_df(bucket,meta_key)\n",
    "    df_all=pd.concat([df_old,df_new])\n",
    "    write_df_to_s3_csv(bucket,df_all, meta_key)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b89aef",
   "metadata": {},
   "source": [
    "# Main Function Entrypoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3dcbfa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    #parameters/configurations\n",
    "    # all data after arg_date\n",
    "    arg_date = '2022-09-19'\n",
    "    src_format = '%Y-%m-%d'\n",
    "    #meta_file\n",
    "    meta_key='meta_file.csv'\n",
    "    #source bucket\n",
    "    src_bucket = 'xetra-1234'\n",
    "    #target bucket\n",
    "    trg_bucket = 'jiaxin-etl'\n",
    "    #colums that we need\n",
    "    columns = ['ISIN', 'Date', 'Time', 'StartPrice', 'MaxPrice', 'MinPrice', 'EndPrice', 'TradedVolume']\n",
    "    #target key\n",
    "    trg_key='xetra_daily_report_'\n",
    "    #save format\n",
    "    trg_format='.parquet'\n",
    "    \n",
    "    #init connections\n",
    "    s3 = boto3.resource('s3')\n",
    "    bucket_src = s3.Bucket(src_bucket)\n",
    "    bucket_trg = s3.Bucket(trg_bucket)\n",
    "    \n",
    "    #data pipeline, etl,run application\n",
    "    extract_date,date_list=return_date_list(bucket_trg, arg_date,src_format,meta_key)\n",
    "    etl_report1(bucket_src,bucket_trg,date_list,columns,arg_date,trg_key,trg_format,meta_key)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff2bdae",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "58be2d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c84ab2d",
   "metadata": {},
   "source": [
    "### reading the upload file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0fce7087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta_file.csv\n",
      "xetra_daily_report_20220924_033348.parquet\n",
      "xetra_daily_report_20220924_041827.parquet\n",
      "xetra_daily_report_20220924_181929.parquet\n",
      "xetra_daily_report_20220924_182555.parquet\n",
      "xetra_daily_report_20220924_185934.parquet\n",
      "xetra_daily_report_20220924_190342.parquet\n"
     ]
    }
   ],
   "source": [
    "trg_bucket = 'jiaxin-etl'\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_trg = s3.Bucket(trg_bucket)\n",
    "\n",
    "for obj in bucket_trg.objects.all():\n",
    "    print(obj.key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "da3ca7f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISIN</th>\n",
       "      <th>Date</th>\n",
       "      <th>opening_price_eur</th>\n",
       "      <th>closing_price_eur</th>\n",
       "      <th>minimum_price_eur</th>\n",
       "      <th>maximum_price_eur</th>\n",
       "      <th>daily_traded_volume</th>\n",
       "      <th>change_prev_closing_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AT000000STR1</td>\n",
       "      <td>2022-09-22</td>\n",
       "      <td>36.40</td>\n",
       "      <td>36.85</td>\n",
       "      <td>36.40</td>\n",
       "      <td>36.85</td>\n",
       "      <td>1475</td>\n",
       "      <td>-1.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AT000000STR1</td>\n",
       "      <td>2022-09-23</td>\n",
       "      <td>37.00</td>\n",
       "      <td>37.95</td>\n",
       "      <td>37.00</td>\n",
       "      <td>37.95</td>\n",
       "      <td>396</td>\n",
       "      <td>2.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AT000000STR1</td>\n",
       "      <td>2022-09-24</td>\n",
       "      <td>36.05</td>\n",
       "      <td>36.35</td>\n",
       "      <td>35.65</td>\n",
       "      <td>37.05</td>\n",
       "      <td>1838</td>\n",
       "      <td>-4.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AT00000FACC2</td>\n",
       "      <td>2022-09-22</td>\n",
       "      <td>7.89</td>\n",
       "      <td>8.47</td>\n",
       "      <td>7.89</td>\n",
       "      <td>8.47</td>\n",
       "      <td>1956</td>\n",
       "      <td>1.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AT00000FACC2</td>\n",
       "      <td>2022-09-23</td>\n",
       "      <td>8.27</td>\n",
       "      <td>8.36</td>\n",
       "      <td>8.27</td>\n",
       "      <td>8.46</td>\n",
       "      <td>70</td>\n",
       "      <td>-1.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9611</th>\n",
       "      <td>XS2376095068</td>\n",
       "      <td>2022-09-23</td>\n",
       "      <td>33.59</td>\n",
       "      <td>34.09</td>\n",
       "      <td>33.59</td>\n",
       "      <td>34.13</td>\n",
       "      <td>400</td>\n",
       "      <td>3.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9612</th>\n",
       "      <td>XS2376095068</td>\n",
       "      <td>2022-09-24</td>\n",
       "      <td>31.63</td>\n",
       "      <td>31.57</td>\n",
       "      <td>31.57</td>\n",
       "      <td>31.63</td>\n",
       "      <td>3</td>\n",
       "      <td>-7.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9613</th>\n",
       "      <td>XS2434891219</td>\n",
       "      <td>2022-09-22</td>\n",
       "      <td>3.26</td>\n",
       "      <td>3.32</td>\n",
       "      <td>3.26</td>\n",
       "      <td>3.32</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9614</th>\n",
       "      <td>XS2434891219</td>\n",
       "      <td>2022-09-23</td>\n",
       "      <td>3.37</td>\n",
       "      <td>3.42</td>\n",
       "      <td>3.37</td>\n",
       "      <td>3.43</td>\n",
       "      <td>24646</td>\n",
       "      <td>3.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9615</th>\n",
       "      <td>XS2434891219</td>\n",
       "      <td>2022-09-24</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.16</td>\n",
       "      <td>1300</td>\n",
       "      <td>-7.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9616 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ISIN        Date  opening_price_eur  closing_price_eur  \\\n",
       "0     AT000000STR1  2022-09-22              36.40              36.85   \n",
       "1     AT000000STR1  2022-09-23              37.00              37.95   \n",
       "2     AT000000STR1  2022-09-24              36.05              36.35   \n",
       "3     AT00000FACC2  2022-09-22               7.89               8.47   \n",
       "4     AT00000FACC2  2022-09-23               8.27               8.36   \n",
       "...            ...         ...                ...                ...   \n",
       "9611  XS2376095068  2022-09-23              33.59              34.09   \n",
       "9612  XS2376095068  2022-09-24              31.63              31.57   \n",
       "9613  XS2434891219  2022-09-22               3.26               3.32   \n",
       "9614  XS2434891219  2022-09-23               3.37               3.42   \n",
       "9615  XS2434891219  2022-09-24               3.15               3.15   \n",
       "\n",
       "      minimum_price_eur  maximum_price_eur  daily_traded_volume  \\\n",
       "0                 36.40              36.85                 1475   \n",
       "1                 37.00              37.95                  396   \n",
       "2                 35.65              37.05                 1838   \n",
       "3                  7.89               8.47                 1956   \n",
       "4                  8.27               8.46                   70   \n",
       "...                 ...                ...                  ...   \n",
       "9611              33.59              34.13                  400   \n",
       "9612              31.57              31.63                    3   \n",
       "9613               3.26               3.32                    0   \n",
       "9614               3.37               3.43                24646   \n",
       "9615               3.15               3.16                 1300   \n",
       "\n",
       "      change_prev_closing_%  \n",
       "0                     -1.60  \n",
       "1                      2.99  \n",
       "2                     -4.22  \n",
       "3                      1.80  \n",
       "4                     -1.30  \n",
       "...                     ...  \n",
       "9611                   3.17  \n",
       "9612                  -7.40  \n",
       "9613                  -3.33  \n",
       "9614                   3.11  \n",
       "9615                  -7.88  \n",
       "\n",
       "[9616 rows x 8 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prq_obj = bucket_trg.Object(key='xetra_daily_report_20220924_182555.parquet').get().get('Body').read()\n",
    "data = BytesIO(prq_obj)\n",
    "df_report = pd.read_parquet(data)\n",
    "\n",
    "df_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d497ccf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
